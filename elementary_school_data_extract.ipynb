{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from pdfreader import SimplePDFViewer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "budget_adopted_2023_2024_url = 'https://www.seattleschools.org/wp-content/uploads/2023/09/Budget-Book-Final_Web-Version-Adopted.pdf'\n",
    "budget_summary_2023_2024_url = 'https://www.seattleschools.org/wp-content/uploads/2023/09/FY24-Adopted-Budget-Summary-Tables.pdf'\n",
    "facilities_master_plan_2021_url = 'https://www.seattleschools.org/wp-content/uploads/2021/09/2021_Facilities_Master_Plan_Update.pdf'\n",
    "attendance_area_report_url = 'https://www.seattleschools.org/wp-content/uploads/2022/08/Section-4-w-ADA-Cover.pdf'\n",
    "budget='data/budget_adopted_2023_2024.pdf'\n",
    "budget_summary='data/budget_summary_2023_2024.pdf'\n",
    "facilities_master_plan = 'data/facilities_master_plan_2021.pdf'\n",
    "attendance_area_report = 'data/attendance_area_report.pdf'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "data_orig = pd.read_csv('data/sps_data_extract.csv')\n",
    "data = data_orig.copy()\n",
    "\n",
    "load_fact_schools = pd.read_csv('data/fact_schools.csv')\n",
    "student_attending_live = pd.read_csv('data/fact_student_attending_live.csv')\n",
    "student_live_attending = pd.read_csv('data/fact_student_live_attending.csv')\n",
    "\n",
    "#Fact Schools - due to misspelled school names in the PDFs\n",
    "fact_schools = pd.merge(load_fact_schools, load_fact_schools, how='left', left_on='Primary Index', right_on='Index')[['School_x','Index_x','School_y','Index_y', 'School Type_y']]\\\n",
    "    .rename(columns={'School_x':'Text','School_y':'School', 'Index_y':'Key', 'Index_x':'Index', 'School Type_y':'Type'})[['Key','Text','School','Index','Type']]\n",
    "\n",
    "#Fact Students Living in Attendance Areas...\n",
    "x = pd.merge(student_live_attending,fact_schools,right_on='Text', left_on='Attendance Area', how='left', suffixes=['_x','_y'])\\\n",
    "    .drop(columns=['Attendance Area','Text'])\\\n",
    "    .rename(columns={'School_y':'Attendance Area', 'School_x':'School'})[['Attendance Area','School','Count']]\n",
    "y = pd.merge(x,fact_schools,right_on='Text', left_on='School', how='left', suffixes=['_x','_y'])\\\n",
    "    .drop(columns=['School_x','Text'])\\\n",
    "    .rename(columns={'School_y':'School'})[['Attendance Area','School','Count']]\n",
    "fact_student_live_attending = y.copy()\n",
    "fact_student_live_attending\n",
    "\n",
    "#Fact Students Attending Schools Live... \n",
    "x = pd.merge(student_attending_live,fact_schools,right_on='Text', left_on='Attending School', how='left', suffixes=['_x','_y'])\\\n",
    "    .drop(columns=['Attending School','Text'])\\\n",
    "    .rename(columns={'School':'Attending School'})[['Attending School','Live Location','Count']]\n",
    "y = pd.merge(x,fact_schools,right_on='Text', left_on='Live Location', how='left', suffixes=['_x','_y'])\\\n",
    "    .drop(columns=['Text', 'Live Location'])\\\n",
    "    .rename(columns={'School':'Live Location'})[['Attending School','Live Location','Count']]\n",
    "fact_student_attending_live = y.copy()\n",
    "fact_student_attending_live\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "#   Functions listed here: \n",
    "########################################################################################\n",
    "\n",
    "def get_lat_long(address, api_key):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'results' in data and len(data['results']) > 0:\n",
    "            location = data['results'][0]['geometry']['location']\n",
    "            return location['lat'], location['lng']\n",
    "    return None, None\n",
    "\n",
    "def rename_school(s): \n",
    "    s1 = s.strip()\n",
    "    return pd.merge(fact_schools[['School','Text']],pd.DataFrame(data={'School': [s1]}),left_on='Text',right_on='School',how='right')['School_x'][0]\n",
    "\n",
    "\n",
    "def split_string(s):\n",
    "    match = re.match(r\"(.*?)(\\d+)$\", s)\n",
    "    if match:\n",
    "        non_numeric = match.group(1)\n",
    "        numeric = match.group(2)\n",
    "        return non_numeric, int(numeric)\n",
    "    else:\n",
    "        raise ValueError(\"The string does not end with a numeric part\")\n",
    "    \n",
    "\n",
    "def create_df_from_split_string(s):\n",
    "    df = pd.DataFrame([split_string(x) for x in s])\n",
    "    df.columns = ['School','Count']\n",
    "    return df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_distance(coord1, coord2):\n",
    "    return geodesic(coord1, coord2).miles\n",
    "\n",
    "\n",
    "def convert_to_float(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.replace(',', ''))\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, page_num):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num]\n",
    "        tables = page.extract_tables()\n",
    "        \n",
    "        dataframes = []\n",
    "        for table in tables:\n",
    "            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "            dataframes.append(df)\n",
    "        return dataframes\n",
    "\n",
    "def find_dataframe_with_column(dfs, column_name):\n",
    "    for idx, df in enumerate(dfs):\n",
    "        if column_name in df.columns:\n",
    "            return idx\n",
    "    return -1  # Return -1 if the column name is not found in any DataFrame\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, page_num):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        viewer = SimplePDFViewer(file)\n",
    "        viewer.navigate(page_num + 1)\n",
    "        viewer.render()\n",
    "        return \"\".join(viewer.canvas.strings)\n",
    "\n",
    "def get_budget_table(page_num, include_school=True, pivoted=True):\n",
    "    # First extract the tables from the PDF\n",
    "    dataframes = extract_tables_from_pdf(budget, page_num)\n",
    "\n",
    "    # Find the DataFrame that contains the budget table, it varies by page because of nuances with PDFPlumber\n",
    "    budget_table_index = find_dataframe_with_column(dataframes,'School Year\\nFunding Type 21-22 22-23 23-24')\n",
    "    budget_table_b = dataframes[budget_table_index][[None]][None].str.split(' ', expand=True)\n",
    "    budget_table_a = dataframes[budget_table_index].iloc[:, 0:1]\n",
    "\n",
    "    # Overwrite the column names with the correct ones, Merge the two DataFrames    \n",
    "    budget_table_a.columns = ['Budget']\n",
    "    budget_table_b.columns = ['2021-22', '2022-23', '2023-24']\n",
    "    budget_table = pd.merge(budget_table_a, budget_table_b, left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    # Append the string BUDGET to indicate it is the budget data\n",
    "    budget_table['Budget'] = budget_table['Budget'].apply(lambda x: x + ' (BUDGET)')\n",
    "\n",
    "    # Clean up the DataFrame and cast numeric values to floats.\n",
    "    budget_table['2021-22'] = budget_table['2021-22'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "    budget_table['2022-23'] = budget_table['2022-23'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "    budget_table['2023-24'] = budget_table['2023-24'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "    if pivoted: \n",
    "        budget_table = budget_table.pivot_table(columns='Budget', values=['2023-24','2022-23','2021-22'], aggfunc='sum') \n",
    "        budget_table.columns.name = 'Index'\n",
    "        budget_table = budget_table.reset_index().rename(columns={'index':'Year'})\n",
    "\n",
    "\n",
    "    # Find the school name and add it to the DataFrame using a weird string in the PDF to identify the school name\n",
    "    raw_text = extract_text_from_pdf(budget,page_num)\n",
    "    if include_school:\n",
    "        school_name = raw_text[0:raw_text.find('A.2023-24')]\n",
    "        # Lots of akas for school names in the PDF and website\n",
    "        if (school_name == 'Cascadia Elementrary'):\n",
    "            school_name = 'Cascadia Elementary'\n",
    "        elif (school_name == 'Rising Star Academy'): \n",
    "            school_name = 'Rising Star Elementary'\n",
    "        elif (school_name == 'John Stanford Elementary'): \n",
    "            school_name = 'John Stanford International Elementary'\n",
    "        elif (school_name == 'Northgate Elementary'): \n",
    "            school_name = 'James Baldwin Elementary'\n",
    "        elif (school_name == 'McDonald Intl. Elementary'): \n",
    "            school_name = 'McDonald International Elementary'\n",
    "        elif (school_name == 'Madrona K-5'): \n",
    "            school_name = 'Madrona Elementary'\n",
    "        elif (school_name == 'Martin Luther King Jr. Elementary'): \n",
    "            school_name = 'Martin Luther King, Jr. Elementary'\n",
    "        elif (school_name == 'Genesse Hill Elementary'): \n",
    "            school_name = 'Genesee Hill Elementary'\n",
    "        elif (school_name == 'Dearborn Park Intl. Elementary'): \n",
    "            school_name = 'Dearborn Park International Elementary'\n",
    "        elif (school_name == 'B.F. Day Elementary'): \n",
    "            school_name = 'Benjamin Franklin Day Elementary'\n",
    "        elif (school_name == 'Concord Intl. Elementary'): \n",
    "            school_name = 'Concord International Elementary'\n",
    "        elif (school_name == 'Franz Coe Elementary'): \n",
    "            school_name = 'Coe Elementary'\n",
    "        elif (school_name == 'Beacon Hill Intl. Elementary'): \n",
    "            school_name = 'Beacon Hill International Elementary'\n",
    "        budget_table['School'] = school_name\n",
    "        col_to_move = budget_table.columns[-1]\n",
    "        budget_table = budget_table[[col_to_move] + [col for col in budget_table.columns if col != col_to_move]]\n",
    "\n",
    "    # Reorder the columns, Return the final dataframe\n",
    "    return budget_table\n",
    "\n",
    "\n",
    "def get_demographics_table(page_num, include_school=True, pivoted=True):\n",
    "    # First extract the tables from the PDF\n",
    "    dataframes = extract_tables_from_pdf(budget, page_num)\n",
    "\n",
    "    # Find the DataFrame that contains the budget table, it varies by page because of nuances with PDFPlumber\n",
    "    demographics_table_index = find_dataframe_with_column(dataframes,'School Year\\n21-22 22-23 23-24')\n",
    "    demographics_table_b = dataframes[demographics_table_index][[None]][None].str.split(' ', expand=True)\n",
    "    demographics_table_a = dataframes[demographics_table_index].iloc[:, 0:1]    \n",
    "\n",
    "    # Overwrite the column names with the correct ones, Merge the two DataFrames    \n",
    "    demographics_table_a.columns = ['Demographic']\n",
    "    demographics_table_b.columns = ['2021-22', '2022-23', '2023-24']\n",
    "    demographics_table = pd.merge(demographics_table_a, demographics_table_b, left_index=True, right_index=True)\n",
    "\n",
    "    # Append the string ENROLLMENT to indicate it is the enrollment data\n",
    "    demographics_table['Demographic'] = demographics_table['Demographic'].apply(lambda x: x + ' (ENROLLMENT)')\n",
    "\n",
    "    # Find the school name and add it to the DataFrame using a weird string in the PDF to identify the school name\n",
    "    raw_text = extract_text_from_pdf(budget,page_num)\n",
    "\n",
    "    if pivoted: \n",
    "        demographics_table = demographics_table.pivot_table(columns='Demographic', values=['2023-24','2022-23','2021-22'], aggfunc='sum') \n",
    "        demographics_table.columns.name = 'Index'\n",
    "        demographics_table = demographics_table.reset_index().rename(columns={'index':'Year'})\n",
    "\n",
    "    if include_school:\n",
    "        school_name = raw_text[0:raw_text.find('A.2023-24')]\n",
    "        # Cascadia Elementary is the only school with a typo in the PDF\n",
    "        if (school_name == 'Cascadia Elementrary'):\n",
    "            school_name = 'Cascadia Elementary'\n",
    "        elif (school_name == 'Rising Star Academy'): \n",
    "            school_name = 'Rising Star Elementary'\n",
    "        elif (school_name == 'John Stanford Elementary'): \n",
    "            school_name = 'John Stanford International Elementary'\n",
    "        elif (school_name == 'Northgate Elementary'): \n",
    "            school_name = 'James Baldwin Elementary'\n",
    "        elif (school_name == 'McDonald Intl. Elementary'): \n",
    "            school_name = 'McDonald International Elementary'\n",
    "        elif (school_name == 'Madrona K-5'): \n",
    "            school_name = 'Madrona Elementary'\n",
    "        elif (school_name == 'Martin Luther King Jr. Elementary'): \n",
    "            school_name = 'Martin Luther King, Jr. Elementary'\n",
    "        elif (school_name == 'Genesse Hill Elementary'): \n",
    "            school_name = 'Genesee Hill Elementary'\n",
    "        elif (school_name == 'Dearborn Park Intl. Elementary'): \n",
    "            school_name = 'Dearborn Park International Elementary'\n",
    "        elif (school_name == 'B.F. Day Elementary'): \n",
    "            school_name = 'Benjamin Franklin Day Elementary'\n",
    "        elif (school_name == 'Concord Intl. Elementary'): \n",
    "            school_name = 'Concord International Elementary'\n",
    "        elif (school_name == 'Franz Coe Elementary'): \n",
    "            school_name = 'Coe Elementary'\n",
    "        elif (school_name == 'Beacon Hill Intl. Elementary'): \n",
    "            school_name = 'Beacon Hill International Elementary'\n",
    "        demographics_table['School'] = school_name\n",
    "        col_to_move = demographics_table.columns[-1]\n",
    "        demographics_table = demographics_table[[col_to_move] + [col for col in demographics_table.columns if col != col_to_move]]\n",
    "\n",
    "    # Reorder the columns, Return the final dataframe\n",
    "    return demographics_table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_facility_table(Use='E'):\n",
    "    facility_inventory_table_page1 = 27\n",
    "    facility_inventory_table_page2 = 28\n",
    "    facility_inventory_table_page3 = 29\n",
    "\n",
    "    a1 = extract_tables_from_pdf(facilities_master_plan,facility_inventory_table_page1)\n",
    "    a2 = extract_tables_from_pdf(facilities_master_plan,facility_inventory_table_page2)\n",
    "    a3 = extract_tables_from_pdf(facilities_master_plan,facility_inventory_table_page3)\n",
    "\n",
    "    t1 = a1[0] # First and only table for each page is the one we want\n",
    "    t2 = a2[0]\n",
    "    t3 = a3[0]\n",
    "\n",
    "\n",
    "    columns = [\"Use\",\"School\",\n",
    "            \"Classification\",\"Address\",\n",
    "            \"Landmark\",\"Building Area (Gross sf)\",\n",
    "            \"Building Area (SCAP Recognized sf)\",\n",
    "            \"Site Area (acre)\",\"Date of Construction\",\n",
    "            \"Date of Last Full Reno\",\"Levy (1985-2019)\"\n",
    "            ]\n",
    "\n",
    "    t1.columns = columns # Assigning column names to the table\n",
    "    t2.columns = columns\n",
    "    t3.columns = columns\n",
    "\n",
    "    #t1.drop(0,inplace=True) \n",
    "    t2.drop(0,inplace=True) # Dropping the first row which contains the column names, but it gets the first table right for whatever reason.\n",
    "    t3.drop(0,inplace=True)\n",
    "\n",
    "    t3.drop(23,inplace=True) # Dropping the last row which contains the key/legend for the table\n",
    "\n",
    "    t1.replace('','Y', regex=True, inplace=True) # Replacing the checkmark symbol with 'Y'\n",
    "    t2.replace('','Y', regex=True, inplace=True)\n",
    "    t3.replace('','Y', regex=True, inplace=True)\n",
    "\n",
    "    t1['School'] = t1['School'].str.replace('\\n',' ') # Removing the Newline character from the School column\n",
    "    t1['School'] = t1['School'].str.replace('*','') # Removing the asterisk symbol from the School column\n",
    "    t2['School'] = t2['School'].str.replace('\\n',' ') # Removing the Newline character from the School column\n",
    "    t2['School'] = t2['School'].str.replace('*','') # Removing the asterisk symbol from the School column\n",
    "    t3['School'] = t3['School'].str.replace('\\n',' ') # Removing the Newline character from the School column\n",
    "    t3['School'] = t3['School'].str.replace('*','') # Removing the asterisk symbol from the School column\n",
    "\n",
    "    t1_names_fixed = pd.merge(t1,fact_schools, left_on='School', right_on='Text',how='inner').query(f'Type == \"{Use}\"').drop(columns=['School_x','Index','Type','Text']).rename(columns={'School_y':'School'})\n",
    "    t2_names_fixed = pd.merge(t2,fact_schools, left_on='School', right_on='Text',how='inner').query(f'Type == \"{Use}\"').drop(columns=['School_x','Index','Type','Text']).rename(columns={'School_y':'School'})\n",
    "    t3_names_fixed = pd.merge(t3,fact_schools, left_on='School', right_on='Text',how='inner').query(f'Type == \"{Use}\"').drop(columns=['School_x','Index','Type','Text']).rename(columns={'School_y':'School'})\n",
    "    t = pd.concat([t1_names_fixed,t2_names_fixed,t3_names_fixed])\n",
    "    facility_inventory = pd.merge(fact_schools.query(f'Type == \"{Use}\" and Key == Index'),t, on='School', how='left').drop(columns=['Type','Index', 'Key_x', 'Key_y','Text'])\n",
    "    facility_inventory['Levy (1985-2019)'] = facility_inventory['Levy (1985-2019)'].str.replace('\\n',' ') # Removing the Newline character from the Levy column\n",
    "    return facility_inventory\n",
    "\n",
    "\n",
    "\n",
    "def redistribute_students(school_of_interest='Dunlap Elementary'):\n",
    "\n",
    "        school_of_interest = rename_school(school_of_interest)\n",
    "        try: \n",
    "                weighted_distribution_total = \\\n",
    "                        fact_student_attending_live.query(f'`Attending School` == \"{school_of_interest}\" and `Attending School` == `Live Location`')['Count'].values[0]\n",
    "        except: \n",
    "                weighted_distribution_total = 1\n",
    "\n",
    "        redistributed_students = \\\n",
    "                fact_student_attending_live.query(f'`Attending School` == \"{school_of_interest}\" and `Attending School` != `Live Location`')\\\n",
    "                .rename(columns={'Attending School':'From', 'Live Location':'To'})\n",
    "\n",
    "        w1 = fact_student_live_attending.query(f'`Attendance Area` == \"{school_of_interest}\" and `Attendance Area` != `School`')\n",
    "        w1['Weighted Count'] = (w1['Count'] / w1['Count'].sum()) * weighted_distribution_total\n",
    "        w1 = w1.drop(columns=['Count']).rename(columns={'Attendance Area':'From', 'School':'To', 'Weighted Count':'Count'})[['From','To','Count']]\n",
    "\n",
    "        redistributed_students = pd.concat([redistributed_students,w1], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "        return redistributed_students.groupby('To')['Count'].sum().reset_index().sort_values(by='Count', ascending=False).reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "def redistribute_students_vector(school_of_interest='Dunlap Elementary'):\n",
    "\n",
    "    school_of_interest = rename_school(school_of_interest)\n",
    "    try: \n",
    "            weighted_distribution_total = \\\n",
    "                    fact_student_attending_live.query(f'`Attending School` == \"{school_of_interest}\" and `Attending School` == `Live Location`')['Count'].values[0]\n",
    "    except: \n",
    "            weighted_distribution_total = 1\n",
    "\n",
    "    redistributed_students = \\\n",
    "            fact_student_attending_live.query(f'`Attending School` == \"{school_of_interest}\" and `Attending School` != `Live Location`')\\\n",
    "            .rename(columns={'Attending School':'From', 'Live Location':'To'})\n",
    "\n",
    "    w1 = fact_student_live_attending.query(f'`Attendance Area` == \"{school_of_interest}\" and `Attendance Area` != `School`')\n",
    "    w1['Weighted Count'] = (w1['Count'] / w1['Count'].sum()) * weighted_distribution_total\n",
    "    w1 = w1.drop(columns=['Count']).rename(columns={'Attendance Area':'From', 'School':'To', 'Weighted Count':'Count'})[['From','To','Count']]\n",
    "\n",
    "    redistributed_students = pd.concat([redistributed_students,w1], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    x = redistributed_students.groupby('To')['Count'].sum().reset_index().sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    x['weighted'] = (x['Count'] / x['Count'].sum())\n",
    "    x = x.drop(columns=['Count']).rename(columns={'To':'School','weighted':'Weight'})\n",
    "    return pd.merge(x,pd.DataFrame(data['School'].unique(),columns=['School']),on='School',how='right').fillna(0).reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Build the Budget Table: \n",
    "########################################################################################\n",
    "x = None\n",
    "\n",
    "for i in range(67,129): #Pages 67-129 are for elementary schools\n",
    "    if (x is None):\n",
    "        x = get_budget_table(i)\n",
    "    else:\n",
    "        x = pd.concat([x,get_budget_table(i)], ignore_index=True)\n",
    "    print(f\"{i}, \", end=\"\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Build the Demographics Table: \n",
    "########################################################################################\n",
    "y = None\n",
    "\n",
    "for i in range(67,129): #Pages 67-129 are for elementary schools\n",
    "    if (y is None):\n",
    "        y = get_demographics_table(i)\n",
    "    else:\n",
    "        y = pd.concat([y,get_demographics_table(i)], ignore_index=True)\n",
    "    print(f\"{i}, \", end=\"\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Get Addresses and Lat/Longs \n",
    "########################################################################################\n",
    "coords = None\n",
    "\n",
    "for i in range(1,8): \n",
    "\n",
    "    # URL of the page to scrape    \n",
    "    url = f'https://www.seattleschools.org/schools/type/elementary/page/{i}/'\n",
    "\n",
    "    # Send a request to fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception if the request was unsuccessful\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all elements that contain school information\n",
    "    school_elements = soup.find_all('div', class_='list-item')\n",
    "\n",
    "    # Prepare lists to store school names and addresses\n",
    "    schools = []\n",
    "    addresses = []\n",
    "\n",
    "    # Loop through each school element to extract names and addresses\n",
    "    for school_element in school_elements:\n",
    "        name_element = school_element.find('h4', class_='list-item-title').find('a')\n",
    "        address_element = school_element.find('address')\n",
    "\n",
    "        if name_element and address_element:\n",
    "            school_name = name_element.get_text(strip=True)\n",
    "            address = address_element.get_text(separator=\" \", strip=True)\n",
    "            \n",
    "            schools.append(school_name)\n",
    "            addresses.append(address)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    data = {\n",
    "        'School': schools,\n",
    "        'Full Address': addresses\n",
    "    }\n",
    "    if coords is None:\n",
    "        coords = pd.DataFrame(data)\n",
    "    else: \n",
    "        coords = pd.concat([coords,pd.DataFrame(data)], ignore_index=True) \n",
    "\n",
    "# Remove trailing text from the addresses\n",
    "api_key = os.getenv('GOOGLE_MAPS_API_KEY')\n",
    "coords['Full Address'] = coords['Full Address'].apply(lambda x: x[0:x.find('About')])\n",
    "coords['Latitude'], coords['Longitude'] = zip(*coords['Full Address'].apply(lambda x: get_lat_long(x, api_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Calculate nearest schools: \n",
    "########################################################################################\n",
    "\n",
    "\n",
    "for index, row in coords.iterrows():\n",
    "    min_distance = float('inf')\n",
    "    closest_school = None\n",
    "    school_coords = (row['Latitude'], row['Longitude'])\n",
    "\n",
    "    for idx, other_row in coords.iterrows():\n",
    "        if index != idx:\n",
    "            other_school_coords = (other_row['Latitude'], other_row['Longitude'])\n",
    "            distance = calculate_distance(school_coords, other_school_coords)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_school = other_row['School']\n",
    "\n",
    "    coords.at[index, 'Closest School'] = closest_school\n",
    "    coords.at[index, 'Distance to Closest School (miles)'] = min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Merge all DFs together, create one as 'z': \n",
    "########################################################################################\n",
    "\n",
    "\n",
    "z = pd.merge(x,y, on=['School','Year'])\n",
    "z = pd.merge(z,coords, how='left', on='School')\n",
    "\n",
    "# Calculate helpful additional columns from existing data and cast numeric values to floats\n",
    "z['Budget Efficiency'] = z['Total Budget (BUDGET)'].astype(float) / z['Total AAFTE* Enrollment (ENROLLMENT)'].astype(float)\n",
    "z['Total AAFTE* Enrollment (ENROLLMENT)'] = z['Total AAFTE* Enrollment (ENROLLMENT)'].astype(float)\n",
    "\n",
    "z.to_csv('data/sps_data_extract.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   Sandbox and Playground Below: \n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[z['School'] == 'Decatur Elementary']\n",
    "\n",
    "# Group by school and calculate the average budget efficiency\n",
    "school_performance = z.groupby('School').agg({\n",
    "    'Budget Efficiency': 'mean',\n",
    "    'Total AAFTE* Enrollment (ENROLLMENT)': 'mean',\n",
    "    'Bilingual Education (BUDGET)': 'mean',\n",
    "    'Special Education (BUDGET)': 'mean',\n",
    "    'General Education (BUDGET)': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Sort schools by budget efficiency in descending order to identify top-performing schools\n",
    "top_schools = school_performance.sort_values(by='Budget Efficiency', ascending=False).head(10)\n",
    "top_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the change in enrollment for each school\n",
    "enrollment_changes = z.pivot_table(index='School', columns='Year', values='Total AAFTE* Enrollment (ENROLLMENT)')\n",
    "\n",
    "# Calculate the difference between the first and last year for each school\n",
    "enrollment_changes['Change'] = enrollment_changes.iloc[:, -1] - enrollment_changes.iloc[:, 0]\n",
    "\n",
    "# Sort schools by enrollment change in ascending order to find the sharpest decline\n",
    "sharpest_decline = enrollment_changes.sort_values(by='Change').head(10)\n",
    "\n",
    "# Sort schools by enrollment change in descending order to find the highest increase\n",
    "highest_increase = enrollment_changes.sort_values(by='Change', ascending=False).head(10)\n",
    "\n",
    "sharpest_decline, highest_increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Study of Cascadia Elementary School - which was closed in 2023\n",
    "cascadia_data = z[z['School'] == 'Cascadia Elementary']\n",
    "\n",
    "# Extract relevant columns for Cascadia Elementary\n",
    "cascadia_summary = cascadia_data[['Year', 'Total AAFTE* Enrollment (ENROLLMENT)', 'Budget Efficiency',\n",
    "                                  'Bilingual Education (BUDGET)', 'Special Education (BUDGET)', 'General Education (BUDGET)']]\n",
    "\n",
    "# Display Cascadia Elementary summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detailed trends for Cascadia Elementary\n",
    "\n",
    "# Calculate year-on-year changes in enrollment and budget efficiency for Cascadia\n",
    "cascadia_data['Enrollment Change'] = cascadia_data['Total AAFTE* Enrollment (ENROLLMENT)'].diff()\n",
    "cascadia_data['Budget Efficiency Change'] = cascadia_data['Budget Efficiency'].diff()\n",
    "\n",
    "# Calculate year-on-year changes in program funding\n",
    "cascadia_data['Bilingual Education Change'] = cascadia_data['Bilingual Education (BUDGET)'].diff()\n",
    "cascadia_data['Special Education Change'] = cascadia_data['Special Education (BUDGET)'].diff()\n",
    "cascadia_data['General Education Change'] = cascadia_data['General Education (BUDGET)'].diff()\n",
    "\n",
    "# Display detailed trends\n",
    "cascadia_data[['Year', 'Total AAFTE* Enrollment (ENROLLMENT)', 'Enrollment Change', 'Budget Efficiency', 'Budget Efficiency Change',\n",
    "               'Bilingual Education (BUDGET)', 'Bilingual Education Change', 'Special Education (BUDGET)', 'Special Education Change',\n",
    "               'General Education (BUDGET)', 'General Education Change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascadia_data[['Year', 'Enrollment Change', 'Budget Efficiency Change',\n",
    "                'Bilingual Education Change', 'Special Education Change',\n",
    "               'General Education Change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################\n",
    "# Prepare data for Clustering Analysis\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "data['Bilingual Education (BUDGET)'] = data['Bilingual Education (BUDGET)'].astype(float)\n",
    "data['General Education (BUDGET)'] = data['General Education (BUDGET)'].astype(float)\n",
    "data['Other Grants (BUDGET)'] = data['Other Grants (BUDGET)'].astype(float)\n",
    "data['Special Education (BUDGET)'] = data['Special Education (BUDGET)'].astype(float)\n",
    "data['State LAP (BUDGET)'] = data['State LAP (BUDGET)'].astype(float)\n",
    "data['Total Budget (BUDGET)'] = data['Total Budget (BUDGET)'].astype(float)\n",
    "data['Bilingual Education (ENROLLMENT)'] = data['Bilingual Education (ENROLLMENT)'].astype(float)\n",
    "data['Free and Reduced Lunch (ENROLLMENT)'] = data['Free and Reduced Lunch (ENROLLMENT)'].astype(float)\n",
    "data['Special Education (ENROLLMENT)'] = data['Special Education (ENROLLMENT)'].astype(float)\n",
    "data['Total AAFTE* Enrollment (ENROLLMENT)'] = data['Total AAFTE* Enrollment (ENROLLMENT)'].astype(float)\n",
    "data['Budget Efficiency'] = data['Budget Efficiency'].astype(float)\n",
    "data['Distance to Closest School (miles)'] = data['Distance to Closest School (miles)'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the numeric data using MinMaxScaler in order to apply K-means clustering fairly on all features\n",
    "#scaler = MinMaxScaler()\n",
    "#numeric_df = data.select_dtypes(include=['float64'])\n",
    "#df_normalized = pd.DataFrame(scaler.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "#data = pd.merge(df_normalized, data.drop(columns=numeric_df.columns), left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Clustering Analysis A: uses all budget and enrollment columns, and budget efficiency\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "# Select relevant columns for clustering\n",
    "columns_to_cluster = [\n",
    "    'Bilingual Education (BUDGET)', 'General Education (BUDGET)', 'Other Grants (BUDGET)', \n",
    "    'Special Education (BUDGET)', 'State LAP (BUDGET)', 'Total Budget (BUDGET)', \n",
    "    'Bilingual Education (ENROLLMENT)', 'Free and Reduced Lunch (ENROLLMENT)', \n",
    "    'Special Education (ENROLLMENT)', 'Total AAFTE* Enrollment (ENROLLMENT)', \n",
    "    'Budget Efficiency'\n",
    "]\n",
    "\n",
    "# Handle missing values by filling with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data[columns_to_cluster])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), sse, marker='o')\n",
    "plt.title('Analysis A: Elbow Method to Determine Optimal k for Clustering')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Apply K-means clustering with k=3\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "clusters_3 = kmeans_3.fit_predict(data_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=4\n",
    "kmeans_4 = KMeans(n_clusters=4, random_state=42)\n",
    "clusters_4 = kmeans_4.fit_predict(data_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=5\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "clusters_5 = kmeans_5.fit_predict(data_scaled)\n",
    "                                  \n",
    "# Apply K-means clustering with k=6\n",
    "kmeans_6 = KMeans(n_clusters=6, random_state=42)\n",
    "clusters_6 = kmeans_6.fit_predict(data_scaled)\n",
    "\n",
    "\n",
    "# Add the cluster labels to the original dataframe\n",
    "data['Cluster_3a'] = clusters_3\n",
    "data['Cluster_4a'] = clusters_4\n",
    "data['Cluster_5a'] = clusters_5\n",
    "data['Cluster_6a'] = clusters_6\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze the clusters by looking at the mean values of the features for each cluster\n",
    "cluster_3a_summary = data.groupby('Cluster_3a')[columns_to_cluster].mean()\n",
    "cluster_4a_summary = data.groupby('Cluster_4a')[columns_to_cluster].mean()\n",
    "cluster_5a_summary = data.groupby('Cluster_5a')[columns_to_cluster].mean()\n",
    "cluster_6a_summary = data.groupby('Cluster_6a')[columns_to_cluster].mean()\n",
    "\n",
    "#cluster_3a_summary, cluster_4a_summary, cluster_5a_summary, cluster_6a_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "## Observations from Clustering Analysis A: \n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#3 Clusters:\n",
    "#Cluster 0: Lower budgets and enrollments.\n",
    "#Cluster 1: Highest budgets and enrollments, especially in bilingual and special education.\n",
    "#Cluster 2: Moderate budget, high total enrollment.\n",
    "\n",
    "\n",
    "#4 Clusters:\n",
    "#Cluster 0: High bilingual education budgets.\n",
    "#Cluster 1: High budgets and enrollments, significant special education funding.\n",
    "#Cluster 2: Lower budgets and enrollments.\n",
    "#Cluster 3: Moderate budgets and enrollments.\n",
    "\n",
    "#5 Clusters:\n",
    "#Cluster 0: High overall budgets and enrollments, particularly in general education and other grants.\n",
    "#Cluster 1: Moderate budgets and enrollments, with a significant amount of state LAP funding.\n",
    "#Cluster 2: Highest budgets, particularly in special education and state LAP, with high enrollments.\n",
    "#Cluster 3: High special education funding and enrollment, moderate budgets.\n",
    "#Cluster 4: Lower budgets and enrollments, with moderate funding in special education and state LAP.\n",
    "\n",
    "#6 Clusters:\n",
    "#Cluster 0: High overall budgets and enrollments, with a significant budget for special education and state LAP.\n",
    "#Cluster 1: Moderate budgets and enrollments, with a notable budget for other grants and a lower budget efficiency.\n",
    "#Cluster 2: Moderate budgets and enrollments with a focus on bilingual education and state LAP.\n",
    "#Cluster 3: Higher budgets and enrollments, particularly in special education and state LAP.\n",
    "#Cluster 4: Highest budgets and enrollments, especially in bilingual education and state LAP.\n",
    "#Cluster 5: Moderate budgets and enrollments, with a significant budget for other grants and a lower budget efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### Clustering Analysis B: excludes state LAP funding, and includes distance to closest school\n",
    "########################################################################################\n",
    "\n",
    "columns_to_cluster = [\n",
    "    'General Education (BUDGET)', 'Other Grants (BUDGET)', 'Special Education (BUDGET)',\n",
    "    'Total Budget (BUDGET)', 'Federal Title I (BUDGET)', 'Bilingual Education (ENROLLMENT)',\n",
    "    'Free and Reduced Lunch (ENROLLMENT)', 'Special Education (ENROLLMENT)',\n",
    "    'Total AAFTE* Enrollment (ENROLLMENT)', 'Budget Efficiency', 'Distance to Closest School (miles)'\n",
    "]\n",
    "\n",
    "\n",
    "# Handle missing values by filling with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data[columns_to_cluster])\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), sse, marker='o')\n",
    "plt.title('Analysis B: Elbow Method to Determine Optimal k for Clustering')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply K-means clustering with k=3\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "clusters_3 = kmeans_3.fit_predict(data_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=4\n",
    "kmeans_4 = KMeans(n_clusters=4, random_state=42)\n",
    "clusters_4 = kmeans_4.fit_predict(data_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=5\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "clusters_5 = kmeans_5.fit_predict(data_scaled)\n",
    "                                  \n",
    "# Apply K-means clustering with k=6\n",
    "kmeans_6 = KMeans(n_clusters=6, random_state=42)\n",
    "clusters_6 = kmeans_6.fit_predict(data_scaled)\n",
    "\n",
    "\n",
    "# Add the cluster labels to the original dataframe\n",
    "data['Cluster_3b'] = clusters_3\n",
    "data['Cluster_4b'] = clusters_4\n",
    "data['Cluster_5b'] = clusters_5\n",
    "data['Cluster_6b'] = clusters_6\n",
    "\n",
    "# Analyze the clusters by looking at the mean values of the features for each cluster\n",
    "cluster_3b_summary = data.groupby('Cluster_3b')[columns_to_cluster].mean()\n",
    "cluster_4b_summary = data.groupby('Cluster_4b')[columns_to_cluster].mean()\n",
    "cluster_5b_summary = data.groupby('Cluster_5b')[columns_to_cluster].mean()\n",
    "cluster_6b_summary = data.groupby('Cluster_6b')[columns_to_cluster].mean()\n",
    "\n",
    "#cluster_3b_summary, cluster_4b_summary, cluster_5b_summary, cluster_6b_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "## Observations from Clustering Analysis B:\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#3 Clusters:\n",
    "#Cluster 0: High budgets in General Education and Other Grants, moderate Special Education budget, relatively high Total Budget. Moderate budget efficiency and average distance to the closest school.\n",
    "#Cluster 1: Moderate budgets across all categories, lower Total Budget. Moderate budget efficiency and slightly higher distance to the closest school.\n",
    "#Cluster 2: High budgets in General Education, low in Other Grants, high Special Education budget, highest Total Budget. Lowest budget efficiency and shortest distance to the closest school.\n",
    "# # # Cluster 2 most likely to be targets for closure. \n",
    "# # # Cluster 0 most likely not to be closed.\n",
    "\n",
    "#4 Clusters:\n",
    "#Cluster 0: High budgets in General Education and Other Grants, moderate Special Education budget, high Total Budget. Moderate budget efficiency and average distance to the closest school.\n",
    "#Cluster 1: Moderate budgets in General Education, low in Other Grants, moderate Special Education budget, moderate Total Budget. Low budget efficiency and longer distance to the closest school.\n",
    "#Cluster 2: High budgets in General Education, low in Other Grants, high Special Education budget, highest Total Budget. Low budget efficiency and average distance to the closest school.\n",
    "#Cluster 3: Low budgets across all categories, lowest Total Budget. Moderate budget efficiency and shortest distance to the closest school.\n",
    "# # # Clusters 2 and 3 most likely to be targets for closure.\n",
    "# # # Clusters 0 and 1 likely not to be closed.\n",
    "\n",
    "#5 Clusters:\n",
    "#Cluster 0: High budgets in General Education and Other Grants, low Special Education budget, moderate Total Budget. High budget efficiency and moderate distance to the closest school.\n",
    "#Cluster 1: Moderate budgets in General Education, low in Other Grants, moderate Special Education budget, moderate Total Budget. Low budget efficiency and longer distance to the closest school.\n",
    "#Cluster 2: High budgets in General Education, moderate in Other Grants, high Special Education budget, high Total Budget. Moderate budget efficiency and average distance to the closest school.\n",
    "#Cluster 3: Low budgets across all categories, low Total Budget. Moderate budget efficiency and shortest distance to the closest school.\n",
    "#Cluster 4: High budgets in General Education, low in Other Grants, high Special Education budget, highest Total Budget. Lowest budget efficiency and average distance to the closest school.\n",
    "# # # Clusters 3 and 4 most likely to be targets for closure.\n",
    "# # # Clusters 0 and 2 likely not to be closed. \n",
    "\n",
    "#6 Clusters:\n",
    "#Cluster 0: High budgets in General Education and Other Grants, low Special Education budget, moderate Total Budget. High budget efficiency and longer distance to the closest school.\n",
    "#Cluster 1: Moderate budgets in General Education, low in Other Grants, moderate Special Education budget, moderate Total Budget. Low budget efficiency and longer distance to the closest school.\n",
    "#Cluster 2: Highest General Education budget, moderate in Other Grants, highest Special Education budget, highest Total Budget. Low budget efficiency and longer distance to the closest school.\n",
    "#Cluster 3: Low budgets across all categories, lowest Total Budget. Moderate budget efficiency and shortest distance to the closest school. Low budget efficiency and longest distance to the closest school.\n",
    "#Cluster 4: High budgets in General Education, low in Other Grants, high Special Education budget, high Total Budget. Lowest budget efficiency and average distance to the closest school.\n",
    "#Cluster 5: High budgets in General Education, low in Other Grants, high Special Education budget, high Total Budget. Moderate budget efficiency and shortest distance to the closest school.\n",
    "# # # Cluster 4 and 5 most likely to be targets for closure.\n",
    "# # # Clusters 0 and 2 most likely not to be closed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### Plots for B analysis\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "scatter_6 = data[['School','Year','Cluster_6b', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_5 = data[['School','Year','Cluster_5b', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_4 = data[['School','Year','Cluster_4b', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_3 = data[['School','Year','Cluster_3b', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "\n",
    "scatter_2023_6b = scatter_6[scatter_6['Year']=='2023-24'].sort_values(by='Cluster_6b')\n",
    "scatter_2022_6b = scatter_6[scatter_6['Year']=='2022-23'].sort_values(by='Cluster_6b')\n",
    "scatter_2021_6b = scatter_6[scatter_6['Year']=='2021-22'].sort_values(by='Cluster_6b')\n",
    "\n",
    "scatter_2023_5b = scatter_5[scatter_5['Year']=='2023-24'].sort_values(by='Cluster_5b')\n",
    "scatter_2022_5b = scatter_5[scatter_5['Year']=='2022-23'].sort_values(by='Cluster_5b')\n",
    "scatter_2021_5b = scatter_5[scatter_5['Year']=='2021-22'].sort_values(by='Cluster_5b')\n",
    "\n",
    "scatter_2023_4b = scatter_4[scatter_4['Year']=='2023-24'].sort_values(by='Cluster_4b')\n",
    "scatter_2022_4b = scatter_4[scatter_4['Year']=='2022-23'].sort_values(by='Cluster_4b')\n",
    "scatter_2021_4b = scatter_4[scatter_4['Year']=='2021-22'].sort_values(by='Cluster_4b')\n",
    "\n",
    "scatter_2023_3b = scatter_3[scatter_3['Year']=='2023-24'].sort_values(by='Cluster_3b')\n",
    "scatter_2022_3b = scatter_3[scatter_3['Year']=='2022-23'].sort_values(by='Cluster_3b')\n",
    "scatter_2021_3b = scatter_3[scatter_3['Year']=='2021-22'].sort_values(by='Cluster_3b')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=6 Clusters B Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_6b)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "cluster_0_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==3].shape[0]\n",
    "cluster_4_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==4].shape[0]\n",
    "cluster_5_size = scatter_2023_6b[scatter_2023_6b['Cluster_6b']==5].shape[0]\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "            f'Cluster 3 ({cluster_3_size})',\n",
    "            f'Cluster 4 ({cluster_4_size})',\n",
    "            f'Cluster 5 ({cluster_5_size})'\n",
    "          ]\n",
    "colors = ['green', 'gray', 'green', 'gray', 'red', 'red']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "#markers = ['o', 's', '^', 'P', 'D', 'X']\n",
    "markers = ['P', 'P', 'P', 'P', 'o', 'o']\n",
    "\n",
    "for cluster in range(6):\n",
    "    cluster_data = df[df['Cluster_6b'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis B: k=6 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=5 Clusters B Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_5b)\n",
    "\n",
    "cluster_0_size = scatter_2023_5b[scatter_2023_5b['Cluster_5b']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_5b[scatter_2023_5b['Cluster_5b']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_5b[scatter_2023_5b['Cluster_5b']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_5b[scatter_2023_5b['Cluster_5b']==3].shape[0]\n",
    "cluster_4_size = scatter_2023_5b[scatter_2023_5b['Cluster_5b']==4].shape[0]\n",
    "\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "            f'Cluster 3 ({cluster_3_size})',\n",
    "            f'Cluster 4 ({cluster_4_size})'\n",
    "          ]\n",
    "colors = ['green', 'gray', 'green', 'red', 'red']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "markers = ['P', 'P', 'P', 'o', 'o']\n",
    "\n",
    "for cluster in range(5):\n",
    "    cluster_data = df[df['Cluster_5b'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis B: k=5 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=4 Clusters B Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_4b)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "\n",
    "cluster_0_size = scatter_2023_4b[scatter_2023_4b['Cluster_4b']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_4b[scatter_2023_4b['Cluster_4b']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_4b[scatter_2023_4b['Cluster_4b']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_4b[scatter_2023_4b['Cluster_4b']==3].shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "            f'Cluster 3 ({cluster_3_size})',\n",
    "          ]\n",
    "colors = ['green', 'green', 'red', 'red']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "markers = ['P', 'P', 'o', 'o']\n",
    "\n",
    "for cluster in range(4):\n",
    "    cluster_data = df[df['Cluster_4b'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis B: k=4 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################\n",
    "### K=3 Clusters B Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_3b)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "\n",
    "cluster_0_size = scatter_2023_3b[scatter_2023_3b['Cluster_3b']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_3b[scatter_2023_3b['Cluster_3b']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_3b[scatter_2023_3b['Cluster_3b']==2].shape[0]\n",
    "\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})'\n",
    "        ]\n",
    "colors = ['green', 'gray', 'red']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "markers = ['P', 'P', 'o']\n",
    "\n",
    "for cluster in range(3):\n",
    "    cluster_data = df[df['Cluster_3b'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis B: k=3 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List of Schools in k-means k=3 and k=4 identified at risk of closure')\n",
    "for i in data.query('(Cluster_3b == 2) and (Cluster_4b in (2,3))')['School'].unique().tolist(): \n",
    "    print(' - '+i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List of Schools in k-means k=3 and k=4 identified safe from closure')\n",
    "for i in data.query('(Cluster_3b == 0) and (Cluster_4b in (0,1))')['School'].unique().tolist(): \n",
    "    print(' - '+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### Clustering Analysis C: Applying Weights to Features, Same Columns as B Analysis\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "columns_to_cluster = [\n",
    "    'General Education (BUDGET)', \n",
    "    'Other Grants (BUDGET)', \n",
    "    'Special Education (BUDGET)',\n",
    "    'Total Budget (BUDGET)', \n",
    "    'Federal Title I (BUDGET)', \n",
    "    'Bilingual Education (ENROLLMENT)',\n",
    "    'Free and Reduced Lunch (ENROLLMENT)', \n",
    "    'Special Education (ENROLLMENT)',\n",
    "    'Total AAFTE* Enrollment (ENROLLMENT)', \n",
    "    'Budget Efficiency', \n",
    "    'Distance to Closest School (miles)'\n",
    "]\n",
    "\n",
    "weights = {\n",
    "    'General Education (BUDGET)':               1, \n",
    "    'Other Grants (BUDGET)':                    1, \n",
    "    'Special Education (BUDGET)':               1,\n",
    "    'Total Budget (BUDGET)':                    1, \n",
    "    'Federal Title I (BUDGET)':                 1, \n",
    "    'Bilingual Education (ENROLLMENT)':         1,\n",
    "    'Free and Reduced Lunch (ENROLLMENT)':      1, \n",
    "    'Special Education (ENROLLMENT)':           1,\n",
    "    'Total AAFTE* Enrollment (ENROLLMENT)':     1, \n",
    "    'Budget Efficiency' :                       2, \n",
    "    'Distance to Closest School (miles)':       4\n",
    "\n",
    "}\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data[columns_to_cluster])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "i=0\n",
    "for column, weight in weights.items():\n",
    "    data_scaled[:,i] *= weight\n",
    "    i+=1\n",
    "\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(data_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), sse, marker='o')\n",
    "plt.title('Analysis C: Elbow Method to Determine Optimal k for Clustering')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Handle missing values by filling with the mean of each column\n",
    "data_imputed = imputer.fit_transform(data[columns_to_cluster])\n",
    "\n",
    "# Normalize the data\n",
    "\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "df_scaled = pd.DataFrame(data_scaled, columns=columns_to_cluster)\n",
    "\n",
    "for column, weight in weights.items():\n",
    "    df_scaled[column] *= weight\n",
    "\n",
    "# Apply K-means clustering with k=3\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "clusters_3 = kmeans_3.fit_predict(df_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=4\n",
    "kmeans_4 = KMeans(n_clusters=4, random_state=42)\n",
    "clusters_4 = kmeans_4.fit_predict(df_scaled)\n",
    "\n",
    "# Apply K-means clustering with k=5\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "clusters_5 = kmeans_5.fit_predict(df_scaled)\n",
    "                                  \n",
    "# Apply K-means clustering with k=6\n",
    "kmeans_6 = KMeans(n_clusters=6, random_state=42)\n",
    "clusters_6 = kmeans_6.fit_predict(df_scaled)\n",
    "\n",
    "\n",
    "# Add the cluster labels to the original dataframe\n",
    "data['Cluster_3c'] = clusters_3\n",
    "data['Cluster_4c'] = clusters_4\n",
    "data['Cluster_5c'] = clusters_5\n",
    "data['Cluster_6c'] = clusters_6\n",
    "\n",
    "# Analyze the clusters by looking at the mean values of the features for each cluster\n",
    "cluster_3c_summary = data.groupby('Cluster_3c')[columns_to_cluster].mean()\n",
    "cluster_4c_summary = data.groupby('Cluster_4c')[columns_to_cluster].mean()\n",
    "cluster_5c_summary = data.groupby('Cluster_5c')[columns_to_cluster].mean()\n",
    "cluster_6c_summary = data.groupby('Cluster_6c')[columns_to_cluster].mean()\n",
    "\n",
    "#cluster_3c_summary, cluster_4c_summary, cluster_5c_summary, cluster_6c_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "## Observations from Clustering Analysis c using weighting: (1,1,1,1,1,1,1,1,1,2,4)\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "#3 Clusters:\n",
    "#Cluster 0: Moderate budgets across all categories, moderate to high enrollment numbers, and below-average budget efficiency, with schools located relatively close to each other.\n",
    "#Cluster 1: High General Education budgets, average enrollment figures, and moderate budget efficiency, with schools located at greater distances.\n",
    "#Cluster 2: Highest General Education budgets, lower enrollments, and higher budget efficiency, with schools moderately spaced apart.\n",
    "# # # Cluster 0 is likely to be target for closure.\n",
    "# # # Cluster 1 is likely not to be closed. \n",
    "\n",
    "#4 Clusters:\n",
    "#Cluster 0: Lower overall budgets, lower enrollments, and moderate budget efficiency, with schools located very close to each other.\n",
    "#Cluster 1: High General Education budgets, higher enrollments, and moderate budget efficiency, with schools located at the greatest distances.\n",
    "#Cluster 2: High General Education budgets, average enrollments, and moderate budget efficiency, with schools moderately spaced apart.\n",
    "#Cluster 3: Highest Total budgets, high enrollments, and the lowest budget efficiency, with schools located relatively close to each other.\n",
    "# # # Cluster 0 most likely to be target for closure.\n",
    "# # # Clusters 1 and 2 likely not to be closed.\n",
    "\n",
    "#5 Clusters:\n",
    "#Cluster 0: Lower overall budgets, lower enrollments, and moderate budget efficiency, with schools located very close to each other.\n",
    "#Cluster 1: High General Education budgets, high enrollments, and moderate budget efficiency, with schools located at the greatest distances.\n",
    "#Cluster 2: Highest General Education budgets, the highest enrollments, and higher budget efficiency, with schools moderately spaced apart\n",
    "#Cluster 3: High budgets, higher enrollments, and the lowest budget efficiency, with schools located relatively close to each other\n",
    "#Cluster 4: Lowest General Education budgets, moderate enrollments, and moderate budget efficiency, with schools moderately spaced apart.\n",
    "# # # Clusters 0 and 3 most likely to be targets for closure.\n",
    "# # # Clusters 1 and 2 likely not to be closed. \n",
    "\n",
    "#6 Clusters:\n",
    "#Cluster 0: Lower overall budgets, lower enrollments, and moderate budget efficiency, with schools located very close to each other.\n",
    "#Cluster 1: Highest Total budgets, highest enrollments, and low budget efficiency, with schools located at the greatest distances\n",
    "#Cluster 2: High General Education budgets, high enrollments, and the highest budget efficiency, with schools moderately spaced apart.\n",
    "#Cluster 3: Have high budgets, high enrollments, and the lowest budget efficiency, with schools located relatively close to each other.\n",
    "#Cluster 4: Moderate budgets, moderate enrollments, and low budget efficiency, with schools moderately spaced apart.\n",
    "#Cluster 5: Moderate budgets, moderate enrollments, and moderate budget efficiency, with schools located at relatively greater distances.\n",
    "# # # Clusters 0 and 3 most likely to be targets for closure.\n",
    "# # # Clusters 1 and 2 most likely not to be closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_6 = data[['School','Year','Cluster_6c', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_5 = data[['School','Year','Cluster_5c', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_4 = data[['School','Year','Cluster_4c', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "scatter_3 = data[['School','Year','Cluster_3c', 'Distance to Closest School (miles)', 'Budget Efficiency']]\n",
    "\n",
    "scatter_2023_6c = scatter_6[scatter_6['Year']=='2023-24'].sort_values(by='Cluster_6c')\n",
    "scatter_2022_6c = scatter_6[scatter_6['Year']=='2022-23'].sort_values(by='Cluster_6c')\n",
    "scatter_2021_6c = scatter_6[scatter_6['Year']=='2021-22'].sort_values(by='Cluster_6c')\n",
    "\n",
    "scatter_2023_5c = scatter_5[scatter_5['Year']=='2023-24'].sort_values(by='Cluster_5c')\n",
    "scatter_2022_5c = scatter_5[scatter_5['Year']=='2022-23'].sort_values(by='Cluster_5c')\n",
    "scatter_2021_5c = scatter_5[scatter_5['Year']=='2021-22'].sort_values(by='Cluster_5c')\n",
    "\n",
    "scatter_2023_4c = scatter_4[scatter_4['Year']=='2023-24'].sort_values(by='Cluster_4c')\n",
    "scatter_2022_4c = scatter_4[scatter_4['Year']=='2022-23'].sort_values(by='Cluster_4c')\n",
    "scatter_2021_4c = scatter_4[scatter_4['Year']=='2021-22'].sort_values(by='Cluster_4c')\n",
    "\n",
    "scatter_2023_3c = scatter_3[scatter_3['Year']=='2023-24'].sort_values(by='Cluster_3c')\n",
    "scatter_2022_3c = scatter_3[scatter_3['Year']=='2022-23'].sort_values(by='Cluster_3c')\n",
    "scatter_2021_3c = scatter_3[scatter_3['Year']=='2021-22'].sort_values(by='Cluster_3c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=6 Clusters C Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_6c)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "cluster_0_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==3].shape[0]\n",
    "cluster_4_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==4].shape[0]\n",
    "cluster_5_size = scatter_2023_6c[scatter_2023_6c['Cluster_6c']==5].shape[0]\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "          f'Cluster 3 ({cluster_3_size})',\n",
    "          f'Cluster 4 ({cluster_4_size})',\n",
    "          f'Cluster 5 ({cluster_5_size})'\n",
    "          ]\n",
    "colors = ['red', 'green', 'green', 'red', 'gray', 'gray']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "#markers = ['o', 's', '^', 'P', 'D', 'X']\n",
    "markers = ['o', 'P', 'P', 'o', 'P', 'P']\n",
    "\n",
    "for cluster in range(6):\n",
    "    cluster_data = df[df['Cluster_6c'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis C: k=6 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=5 Clusters C Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_5c)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "cluster_0_size = scatter_2023_5c[scatter_2023_5c['Cluster_5c']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_5c[scatter_2023_5c['Cluster_5c']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_5c[scatter_2023_5c['Cluster_5c']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_5c[scatter_2023_5c['Cluster_5c']==3].shape[0]\n",
    "cluster_4_size = scatter_2023_5c[scatter_2023_5c['Cluster_5c']==4].shape[0]\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "            f'Cluster 3 ({cluster_3_size})',\n",
    "            f'Cluster 4 ({cluster_4_size})'\n",
    "          ]\n",
    "colors = ['red', 'green', 'green', 'red', 'gray']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "#markers = ['o', 's', '^', 'P', 'D', 'X']\n",
    "markers = ['o', 'P', 'P', 'o', 'P']\n",
    "\n",
    "for cluster in range(5):\n",
    "    cluster_data = df[df['Cluster_5c'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis C: k=5 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=4 Clusters C Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_4c)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "cluster_0_size = scatter_2023_4c[scatter_2023_4c['Cluster_4c']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_4c[scatter_2023_4c['Cluster_4c']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_4c[scatter_2023_4c['Cluster_4c']==2].shape[0]\n",
    "cluster_3_size = scatter_2023_4c[scatter_2023_4c['Cluster_4c']==3].shape[0]\n",
    "cluster_4_size = scatter_2023_4c[scatter_2023_4c['Cluster_4c']==4].shape[0]\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})', \n",
    "            f'Cluster 3 ({cluster_3_size})'\n",
    "          ]\n",
    "colors = ['red', 'green', 'green', 'gray']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "#markers = ['o', 's', '^', 'P', 'D', 'X']\n",
    "markers = ['o', 'P', 'P', 'P']\n",
    "\n",
    "for cluster in range(4):\n",
    "    cluster_data = df[df['Cluster_4c'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis C: k=4 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "### K=3 Clusters C Analysis Plot\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "df = pd.DataFrame(scatter_2023_3c)\n",
    "\n",
    "# Function to add jitter\n",
    "def add_jitter(arr, scale=0.01):\n",
    "    return arr + np.random.randn(len(arr)) * scale\n",
    "\n",
    "cluster_0_size = scatter_2023_3c[scatter_2023_3c['Cluster_3c']==0].shape[0]\n",
    "cluster_1_size = scatter_2023_3c[scatter_2023_3c['Cluster_3c']==1].shape[0]\n",
    "cluster_2_size = scatter_2023_3c[scatter_2023_3c['Cluster_3c']==2].shape[0]\n",
    "\n",
    "\n",
    "labels = [\n",
    "          f'Cluster 0 ({cluster_0_size})', \n",
    "          f'Cluster 1 ({cluster_1_size})', \n",
    "          f'Cluster 2 ({cluster_2_size})'\n",
    "          ]\n",
    "colors = ['red', 'gray', 'green']\n",
    "\n",
    "\n",
    "# Plotting the k=6 clusters with enhancements\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Marker styles\n",
    "#markers = ['o', 's', '^', 'P', 'D', 'X']\n",
    "markers = ['o', 'P', 'P']\n",
    "\n",
    "for cluster in range(3):\n",
    "    cluster_data = df[df['Cluster_3c'] == cluster]\n",
    "    plt.scatter(\n",
    "        cluster_data['Budget Efficiency'], #add_jitter(cluster_data['Budget Efficiency'], 100), \n",
    "        cluster_data['Distance to Closest School (miles)'], #add_jitter(cluster_data['Distance to Closest School (miles)'], 0.01),\n",
    "        color=colors[cluster],\n",
    "        marker=markers[cluster],\n",
    "        label=labels[cluster],\n",
    "        alpha=0.8\n",
    "\n",
    "    )\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Analysis C: k=3 Clusters: Budget Efficiency vs. Distance to Closest School')\n",
    "plt.xlabel('Budget Efficiency')\n",
    "plt.ylabel('Distance to Closest School (miles)')\n",
    "\n",
    "# Creating a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Analysis C: List of Schools in k-means k=3 and k=4 identified at risk of closure')\n",
    "for i in data.query('(Cluster_3c == 0) and (Cluster_4c == 0)')['School'].unique().tolist(): \n",
    "    print(' - '+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Analysis C: List of Schools in k-means k=3 and k=4 identified safe from closure')\n",
    "for i in data.query('(Cluster_3c == 1) and (Cluster_4c in (1,2))')['School'].unique().tolist(): \n",
    "    print(' - '+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facilities = get_facility_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d1 = pd.merge(data,facilities,on='School',how='left')\n",
    "\n",
    "d1['Disadvantage Score'] = (d1['Free and Reduced Lunch (ENROLLMENT)'] + d1['Bilingual Education (ENROLLMENT)'] + d1['Special Education (ENROLLMENT)'])/d1['Total AAFTE* Enrollment (ENROLLMENT)']\n",
    "d1.fillna(0, inplace=True)\n",
    "\n",
    "d1['Year'] = d1['Year'].str.split('-').str[0]\n",
    "d1_orig = d1.copy()\n",
    "d1.drop(columns=['Cluster_3a','Cluster_3b', 'Cluster_4a','Cluster_4b', 'Cluster_5a', 'Cluster_5b', 'Cluster_6a', 'Cluster_6b', 'Cluster_3c', 'Cluster_4c', 'Cluster_5c', 'Cluster_6c'], inplace=True)\n",
    "d1.drop(columns=['Building Area (Gross sf)','Building Area (SCAP Recognized sf)','Site Area (acre)','Date of Construction','School'], inplace=True)\n",
    "d1.drop(columns=['Full Address','Closest School', 'Distance to Closest School (miles)', 'Address','Landmark','Date of Last Full Reno','Levy (1985-2019)','Classification','Latitude','Longitude','Use','Budget Efficiency'], inplace=True)\n",
    "columns_to_drop = [col for col in d1.columns if col.endswith('(BUDGET)') and col not in ['Total Budget (BUDGET)']]\n",
    "d1.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "d2 = d1.query('Year in (\"2023\")').drop(columns=['Year'])\n",
    "d1 = d1.query('Year in (\"2022\",\"2021\")').drop(columns=['Year'])\n",
    "\n",
    "\n",
    "\n",
    "X = d1.copy()\n",
    "X.drop(columns=['Total Budget (BUDGET)'], inplace=True)\n",
    "\n",
    "y = d1.copy()\n",
    "y = y['Total Budget (BUDGET)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#mse = mean_squared_error(y_test, y_pred)\n",
    "#rmse = root_mean_squared_error(y_test, y_pred)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#print(f\"Mean Squared Error: {mse}\")\n",
    "#print(f\"Root Mean Squared Error: {mse}\")\n",
    "#print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "for column in X_train.columns:\n",
    "    X_train[column] = pd.to_numeric(X_train[column], errors='coerce')\n",
    "X_train = X_train.dropna()\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train)  # Adds a constant term to the predictor\n",
    "ols_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "print(ols_model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y-Intercept\n",
    "intercept = ols_model.params[0]\n",
    "formatted_intercept = f\"${intercept:,.2f}\"\n",
    "print(f\"Y-Intercept, Representing the Baseline Cost for Operating an Elementary School : {formatted_intercept}\")\n",
    "\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(ols_model.fittedvalues, ols_model.resid)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# QQ plot\n",
    "sm.qqplot(ols_model.resid, line='s')\n",
    "plt.title('QQ Plot')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Partial regression plots\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "sm.graphics.plot_partregress_grid(ols_model, fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in d2.columns:\n",
    "    d2[column] = pd.to_numeric(d2[column], errors='coerce')\n",
    "\n",
    "new_data = d2.dropna().reset_index(drop=True)\n",
    "new_data_sm = sm.add_constant(new_data.drop(columns=['Total Budget (BUDGET)'])) \n",
    "new_predictions = pd.DataFrame(ols_model.predict(new_data_sm),columns=['Predicted Total Budget (BUDGET)'])\n",
    "new_predictions['Predicted Total Budget (BUDGET)'] = new_predictions['Predicted Total Budget (BUDGET)'].apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "new_data = new_data.join(new_predictions)\n",
    "new_data['Excess Total Budget'] = (new_data['Total Budget (BUDGET)'] - new_data['Predicted Total Budget (BUDGET)']).apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "new_data['Excess Budget per Student'] = (new_data['Excess Total Budget'] / new_data['Total AAFTE* Enrollment (ENROLLMENT)']).apply(lambda x: f\"{x:.2f}\").astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2024 = d1_orig.query('Year in (\"2023\")').reset_index(drop=True).join(new_data,rsuffix='_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_drop = [col for col in performance_2024.columns if col.endswith('_y')]\n",
    "performance_2024.drop(columns=columns_to_drop, inplace=True)\n",
    "performance_2024['Building Area (Gross sf)'] = performance_2024['Building Area (Gross sf)'].apply(convert_to_float)\n",
    "performance_2024['Building Area per Student (sf)'] = (performance_2024['Building Area (Gross sf)'] / performance_2024['Total AAFTE* Enrollment (ENROLLMENT)']).apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "capacity_data = extract_tables_from_pdf(facilities_master_plan,43)[0][2:].rename(columns={'Total\\nEstimated\\nOperational\\nCapacity': 'Capacity'})[['School Name','Capacity']]\n",
    "capacity_data['School'] = capacity_data['School Name'].apply(rename_school)\n",
    "capacity_data = capacity_data.fillna('None')[['School','Capacity']]\n",
    "\n",
    "performance_2024 = pd.merge(performance_2024,capacity_data, on='School', how='left')\n",
    "\n",
    "performance_2024['Excess Capacity'] = performance_2024['Capacity'].astype(int) - performance_2024['Total AAFTE* Enrollment (ENROLLMENT)'].astype(int)\n",
    "performance_2024['Capacity Percent'] = (performance_2024['Total AAFTE* Enrollment (ENROLLMENT)'] / performance_2024['Capacity'].astype(int)).apply(lambda x: f\"{x:.2f}\").astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2024.query('School == \"John Stanford International Elementary\"').transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_2024.to_csv(\"data/performance_data_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_matrix = pd.DataFrame(0,index=facilities['School'].to_list(),columns=facilities['School'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = extract_tables_from_pdf(attendance_area_report, 2)[0]\n",
    "y1.columns[0].split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y1.iloc[1,0].split('\\n')\n",
    "tz = create_df_from_split_string(y1.iloc[1,0].split('\\n'))\n",
    "tz['School_new'] = tz['School'].apply(rename_school)\n",
    "tz.rename(columns={'School_new':'School', 'School':'Old School'}, inplace=True)\n",
    "tz.drop(columns=['Old School'], inplace=True)\n",
    "tz\n",
    "#tz = tz.fillna('None').query('School != \"None\"').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def redistribute_students(student_counts, redistribution_matrix, closed_schools):\n",
    "    # Convert input lists to numpy arrays for easy manipulation\n",
    "    student_counts = np.array(student_counts, dtype=float)\n",
    "    redistribution_matrix = np.array(redistribution_matrix, dtype=float)\n",
    "    closed_schools = set(closed_schools)\n",
    "\n",
    "    # Initialize current student counts\n",
    "    current_student_counts = np.copy(student_counts)\n",
    "    num_schools = len(student_counts)\n",
    "    \n",
    "    while True:\n",
    "        new_counts = np.copy(current_student_counts)\n",
    "        any_redistributed = False\n",
    "        \n",
    "        for school in closed_schools:\n",
    "            if current_student_counts[school] > 0:\n",
    "                any_redistributed = True\n",
    "                total_redistributed = current_student_counts[school]\n",
    "                \n",
    "                # Adjust redistribution percentages to only consider open schools\n",
    "                redistribution_percentages = np.copy(redistribution_matrix[school])\n",
    "                redistribution_percentages[list(closed_schools)] = 0\n",
    "                total_percentage = np.sum(redistribution_percentages)\n",
    "                \n",
    "                if total_percentage > 0:\n",
    "                    redistribution_percentages /= total_percentage\n",
    "                \n",
    "                for i in range(num_schools):\n",
    "                    if i not in closed_schools:\n",
    "                        new_counts[i] += total_redistributed * redistribution_percentages[i]\n",
    "                \n",
    "                new_counts[school] = 0\n",
    "        \n",
    "        if not any_redistributed:\n",
    "            break\n",
    "        \n",
    "        current_student_counts = new_counts\n",
    "    \n",
    "    return current_student_counts\n",
    "\n",
    "# Example usage\n",
    "student_counts = [100, 200, 150, 50]\n",
    "redistribution_matrix = [\n",
    "    [0.0, 0.3, 0.5, 0.2],\n",
    "    [0.4, 0.0, 0.4, 0.2],\n",
    "    [0.3, 0.2, 0.0, 0.5],\n",
    "    [0.5, 0.3, 0.2, 0.0]\n",
    "]\n",
    "closed_schools = [1, 2]\n",
    "\n",
    "new_student_counts = redistribute_students(student_counts, redistribution_matrix, closed_schools)\n",
    "print(f\"New student counts: {new_student_counts}\")\n",
    "print(f\"Total students: {np.sum(new_student_counts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_first_dataframe(df1, df2, column_name):\n",
    "    \"\"\"\n",
    "    Updates the 'df1' dataframe with values from 'df2' based on a specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    df1 (pd.DataFrame): The dataframe to be updated.\n",
    "    df2 (pd.DataFrame): The dataframe providing the updated values.\n",
    "    column_name (str): The column name to base the updates on.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated 'df1' dataframe.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in both dataframes\n",
    "    if column_name not in df1.columns or column_name not in df2.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in both dataframes.\")\n",
    "    \n",
    "    # Iterate over the rows of the second dataframe\n",
    "    for idx, row in df2.iterrows():\n",
    "        if idx in df1.index:\n",
    "            df1.at[idx, column_name] = row[column_name]\n",
    "        else:\n",
    "            df1.loc[idx] = row\n",
    "    \n",
    "    return df1\n",
    "\n",
    "# Example usage:\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [1, 2, 3], 'B': [7, 8, 9]})\n",
    "column_name = 'B'\n",
    "updated_df1 = update_first_dataframe(df1, df2, column_name)\n",
    "print(updated_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alki Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbor Heights Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel Bagley Elementary</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beacon Hill International Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>View Ridge Elementary</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Viewlands Elementary</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Wedgwood Elementary</td>\n",
       "      <td>0.019481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>West Seattle Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>West Woodland Elementary</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  School    Weight\n",
       "0                       Adams Elementary  0.000000\n",
       "1                        Alki Elementary  0.000000\n",
       "2               Arbor Heights Elementary  0.000000\n",
       "3               Daniel Bagley Elementary  0.006494\n",
       "4   Beacon Hill International Elementary  0.000000\n",
       "..                                   ...       ...\n",
       "57                 View Ridge Elementary  0.004870\n",
       "58                  Viewlands Elementary  0.006494\n",
       "59                   Wedgwood Elementary  0.019481\n",
       "60               West Seattle Elementary  0.000000\n",
       "61              West Woodland Elementary  0.001623\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mschools\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'schools' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams Elementary</td>\n",
       "      <td>0.028384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alki Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arbor Heights Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daniel Bagley Elementary</td>\n",
       "      <td>0.034934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beacon Hill International Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>View Ridge Elementary</td>\n",
       "      <td>0.021834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Viewlands Elementary</td>\n",
       "      <td>0.010917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Wedgwood Elementary</td>\n",
       "      <td>0.017467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>West Seattle Elementary</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>West Woodland Elementary</td>\n",
       "      <td>0.015284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  School    Weight\n",
       "0                       Adams Elementary  0.028384\n",
       "1                        Alki Elementary  0.000000\n",
       "2               Arbor Heights Elementary  0.000000\n",
       "3               Daniel Bagley Elementary  0.034934\n",
       "4   Beacon Hill International Elementary  0.000000\n",
       "..                                   ...       ...\n",
       "57                 View Ridge Elementary  0.021834\n",
       "58                  Viewlands Elementary  0.010917\n",
       "59                   Wedgwood Elementary  0.017467\n",
       "60               West Seattle Elementary  0.000000\n",
       "61              West Woodland Elementary  0.015284\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redistribute_students_vector('John Stanford International Elementary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
